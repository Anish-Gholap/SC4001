{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:05.519608Z",
     "start_time": "2025-03-31T10:27:05.512691Z"
    }
   },
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:05.595568Z",
     "start_time": "2025-03-31T10:27:05.578448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(r'data/WASSA-2017/train/anger-ratings-0to1.train.txt', sep='\\t', header=0)\n",
    "test_df = pd.read_csv(r'data/WASSA-2017/test/anger-ratings-0to1.test.target.txt', sep='\\t', header=0)"
   ],
   "id": "a965c20138b9ab8e",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:05.652396Z",
     "start_time": "2025-03-31T10:27:05.638342Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.head()",
   "id": "bd43357494ab8d59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      id                                              tweet tweettype  score\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....     anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...     anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...     anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...     anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...     anger  0.896"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweettype</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ## Load Data",
   "id": "5a071a4b6eb637a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:05.766591Z",
     "start_time": "2025-03-31T10:27:05.754734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "TRAIN_DIR = 'data/WASSA-2017/train'\n",
    "TEST_DIR = 'data/WASSA-2017/test'\n",
    "\n",
    "FILE_PATTERN = '*.txt'\n",
    "LABEL_SEPERATOR = '-'\n",
    "\n",
    "def get_label_from_filename(filename, seperator=LABEL_SEPERATOR):\n",
    "    base_name = os.path.basename(filename)\n",
    "    label = base_name.split(seperator)[0]\n",
    "    return label.lower()\n",
    "\n",
    "def load_data(data_dir, pattern, seperator):\n",
    "    all_files = glob.glob(os.path.join(data_dir, pattern))\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(f\"No files found matching '{pattern}' in directory {data_dir}\")\n",
    "\n",
    "    df_list = []\n",
    "    print(f\"loading files from {data_dir}\")\n",
    "    for filepath in tqdm(all_files, desc=\"Reading files\"):\n",
    "        try:\n",
    "            temp_df = pd.read_csv(filepath, sep='\\t', header=0)\n",
    "            label = get_label_from_filename(filepath, seperator)\n",
    "            temp_df['emotion'] = label\n",
    "            df_list.append(temp_df[['tweet', 'emotion']])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filepath}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not df_list:\n",
    "        raise ValueError(f\"No dataframes were created from files in {data_dir}\")\n",
    "\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"Loaded and combined {len(combined_df)} samples\")\n",
    "    print(f\"Found emotions: {combined_df['emotion'].unique().tolist()}\")\n",
    "    return combined_df"
   ],
   "id": "912d1863fa15b2e",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:05.902698Z",
     "start_time": "2025-03-31T10:27:05.835851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = load_data(data_dir=TRAIN_DIR, pattern=FILE_PATTERN, seperator=LABEL_SEPERATOR)\n",
    "test_df = load_data(data_dir=TEST_DIR, pattern=FILE_PATTERN, seperator=LABEL_SEPERATOR)"
   ],
   "id": "6bcbda6b32018cdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files from data/WASSA-2017/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 167.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and combined 3613 samples\n",
      "Found emotions: ['anger', 'fear', 'joy', 'sadness']\n",
      "loading files from data/WASSA-2017/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 154.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and combined 3142 samples\n",
      "Found emotions: ['anger', 'fear', 'joy', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.078208Z",
     "start_time": "2025-03-31T10:27:06.065556Z"
    }
   },
   "cell_type": "code",
   "source": "train_df",
   "id": "312c65b4bdb8322a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  tweet  emotion\n",
       "0     How the fu*k! Who the heck! moved my fridge!.....    anger\n",
       "1     So my Indian Uber driver just called someone t...    anger\n",
       "2     @DPD_UK I asked for my parcel to be delivered ...    anger\n",
       "3     so ef whichever butt wipe pulled the fire alar...    anger\n",
       "4     Don't join @BTCare they put the phone down on ...    anger\n",
       "...                                                 ...      ...\n",
       "3608  @VivienLloyd Thank you so much! Just home - st...  sadness\n",
       "3609              Just put the winter duvet on ‚òÉÔ∏è‚ùÑÔ∏èüå¨‚òîÔ∏è   sadness\n",
       "3610  @SilkInSide @TommyJoeRatliff that's so pretty!...  sadness\n",
       "3611  @BluesfestByron second artist announcement loo...  sadness\n",
       "3612  I can literally eat creamy pesto pasta topped ...  sadness\n",
       "\n",
       "[3613 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>@VivienLloyd Thank you so much! Just home - st...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>Just put the winter duvet on ‚òÉÔ∏è‚ùÑÔ∏èüå¨‚òîÔ∏è</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>@SilkInSide @TommyJoeRatliff that's so pretty!...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>@BluesfestByron second artist announcement loo...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>I can literally eat creamy pesto pasta topped ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3613 rows √ó 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocess Data",
   "id": "a294481476c376a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.192461Z",
     "start_time": "2025-03-31T10:27:06.186076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter"
   ],
   "id": "80ae1c98561154df",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.273075Z",
     "start_time": "2025-03-31T10:27:06.266106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'stopwords'...\")\n",
    "    nltk.download('stopwords')\n"
   ],
   "id": "49ced68b1f178373",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.440627Z",
     "start_time": "2025-03-31T10:27:06.433594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE_STEMMING = True\n",
    "MIN_WORD_FREQ = 1\n",
    "\n",
    "# --- Special Tokens ---\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\""
   ],
   "id": "1d9e847ec71995e5",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.558080Z",
     "start_time": "2025-03-31T10:27:06.548129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text, processor, stop_words_set):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove punctuations and stop words\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words_set]\n",
    "\n",
    "    if processor:\n",
    "         if isinstance(processor, SnowballStemmer):\n",
    "             # Reduce words to its stem word\n",
    "             processed_tokens = [processor.stem(word) for word in tokens]\n",
    "    else:\n",
    "        processed_tokens = tokens\n",
    "\n",
    "    return processed_tokens\n",
    "\n",
    "def build_vocab(processed_docs, min_freq=1):\n",
    "    \"\"\"Maps words to indices\"\"\"\n",
    "    word_counts = Counter(token for doc in processed_docs for token in doc)\n",
    "    vocab = [word for word, count in word_counts.items() if count >= min_freq]\n",
    "    word_to_idx = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for i, word in enumerate(vocab): word_to_idx[word] = i + 2\n",
    "    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "    vocab_size = len(word_to_idx)\n",
    "    print(f\"Total vocabulary size (including {PAD_TOKEN}, {UNK_TOKEN}): {vocab_size}\")\n",
    "\n",
    "    return word_to_idx, idx_to_word, vocab_size\n",
    "\n",
    "def convert_docs_to_ids(processed_docs, word_to_idx):\n",
    "    \"\"\"Converts list of processed tokens into lists of integer IDs\"\"\"\n",
    "    docs_as_ids = []\n",
    "    for doc in tqdm(processed_docs, desc=\"Converting docs to IDs\"):\n",
    "        docs_as_ids.append([word_to_idx.get(token, word_to_idx[UNK_TOKEN]) for token in doc])\n",
    "\n",
    "    return docs_as_ids"
   ],
   "id": "9e0579921fa61e1c",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.624478Z",
     "start_time": "2025-03-31T10:27:06.616835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_train, labels_train_str = train_df['tweet'].tolist(), train_df['emotion'].tolist()\n",
    "raw_test , labels_test_str = test_df['tweet'].tolist(), test_df['emotion'].tolist()"
   ],
   "id": "f7b4820cc1002420",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:06.647387Z",
     "start_time": "2025-03-31T10:27:06.639429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words_set = set(stopwords.words('english'))\n",
    "stop_words_set.update(string.punctuation)\n",
    "processor = SnowballStemmer('english') if USE_STEMMING else None"
   ],
   "id": "b09d68b4223cb4e0",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:08.708609Z",
     "start_time": "2025-03-31T10:27:06.683941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nProcessing training documents...\")\n",
    "processed_train = [preprocess_text(doc, processor, stop_words_set) for doc in tqdm(raw_train)]\n",
    "print(\"\\nProcessing test documents...\")\n",
    "processed_test = [preprocess_text(doc, processor, stop_words_set) for doc in tqdm(raw_test)]"
   ],
   "id": "bd440f3966e5a555",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing training documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3613/3613 [00:01<00:00, 3265.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3142/3142 [00:00<00:00, 3483.17it/s]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:08.744132Z",
     "start_time": "2025-03-31T10:27:08.715588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nBuilding vocabulary...\")\n",
    "all_processed_docs = processed_train + processed_test\n",
    "word_to_idx, idx_to_word, vocab_size = build_vocab(all_processed_docs, MIN_WORD_FREQ)"
   ],
   "id": "22999caaebc095af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building vocabulary...\n",
      "Total vocabulary size (including <PAD>, <UNK>): 10919\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:08.940723Z",
     "start_time": "2025-03-31T10:27:08.897660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nConverting documents to integer sequences...\")\n",
    "train_ids = convert_docs_to_ids(processed_train, word_to_idx)\n",
    "test_ids = convert_docs_to_ids(processed_test, word_to_idx)"
   ],
   "id": "9a88145adc959379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting documents to integer sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to IDs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3613/3613 [00:00<00:00, 229047.63it/s]\n",
      "Converting docs to IDs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3142/3142 [00:00<00:00, 233190.06it/s]\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:09.162548Z",
     "start_time": "2025-03-31T10:27:09.145885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nProcessing target labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(labels_train_str)\n",
    "y_test = label_encoder.transform(labels_test_str)"
   ],
   "id": "9498febc1b7748f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing target labels...\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:09.344236Z",
     "start_time": "2025-03-31T10:27:09.336146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class mapping (string -> integer): {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")"
   ],
   "id": "93fd9066622b0c04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4\n",
      "Class mapping (string -> integer): {np.str_('anger'): np.int64(0), np.str_('fear'): np.int64(1), np.str_('joy'): np.int64(2), np.str_('sadness'): np.int64(3)}\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:27:09.514869Z",
     "start_time": "2025-03-31T10:27:09.508729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nPreprocessing complete!\")\n",
    "print(f\"Number of training sequences: {len(train_ids)}\")\n",
    "print(f\"Number of test sequences: {len(test_ids)}\")\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ],
   "id": "2c9b9a6f51d21236",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing complete!\n",
      "Number of training sequences: 3613\n",
      "Number of test sequences: 3142\n",
      "Vocabulary Size: 10919\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset and DataLoader",
   "id": "ce214fe036225e27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:44:00.465238Z",
     "start_time": "2025-03-31T10:44:00.456047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        \"\"\"\n",
    "        :param sequences: Preprocessed sequences (samples)\n",
    "        :param labels: Corresponding one hot encoded label for each sequence\n",
    "        \"\"\"\n",
    "\n",
    "        if len(sequences) != len(labels):\n",
    "            raise ValueError(\"Sequences and labels must have the same length\")\n",
    "\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        :param idx: index of sample to be found\n",
    "        :return: sample and its corresponding label as tensors\n",
    "        \"\"\"\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.long)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sequence_tensor, label_tensor"
   ],
   "id": "a8ea0cf372963c68",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:44:02.253867Z",
     "start_time": "2025-03-31T10:44:02.247920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = TweetDataset(train_ids, y_train)\n",
    "test_set = TweetDataset(test_ids, y_test)"
   ],
   "id": "922655239e656ab1",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:44:11.608448Z",
     "start_time": "2025-03-31T10:44:11.601837Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_set)",
   "id": "656d20dad2974b0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3613"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:56:32.264812Z",
     "start_time": "2025-03-31T10:56:32.258272Z"
    }
   },
   "cell_type": "code",
   "source": "train_set[0][1]",
   "id": "806998f1def228bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:51:58.801660Z",
     "start_time": "2025-03-31T10:51:58.794924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_INDEX = 0\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    Collates data samples into batches.\n",
    "\n",
    "    Args:\n",
    "        batch (list of tuple): A list where each element is a tuple\n",
    "                               (sequence_tensor, label_tensor) from the Dataset.\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "               - sequences_padded (Tensor): Batch of padded sequences\n",
    "                 (batch_size, max_len).\n",
    "               - labels (Tensor): Batch of labels (batch_size,).\n",
    "    \"\"\"\n",
    "    label_list, sequence_list = [], []\n",
    "    for (_sequence, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "        sequence_list.append(_sequence) # sequence is already a tensor here\n",
    "\n",
    "    # Pad sequences\n",
    "    # batch_first=True makes output (batch_size, max_seq_len)\n",
    "    sequences_padded = pad_sequence(sequence_list, batch_first=True, padding_value=PAD_INDEX)\n",
    "\n",
    "    # Stack labels\n",
    "    labels = torch.stack(label_list)\n",
    "\n",
    "    return sequences_padded, labels"
   ],
   "id": "509e42a72a88d2",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:52:00.445792Z",
     "start_time": "2025-03-31T10:52:00.437279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAD_INDEX = word_to_idx.get(PAD_TOKEN, 0)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ],
   "id": "93e505586e051ef2",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:54:31.574729Z",
     "start_time": "2025-03-31T10:54:31.565119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = next(iter(train_loader))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "id": "81ec33ca104aefda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "7924173e33be0463"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:36:03.162250Z",
     "start_time": "2025-03-31T11:36:03.153549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_len, hidden_dim, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_len)\n",
    "        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding_layer(x)\n",
    "        output, hidden = self.rnn(embeddings)\n",
    "        return self.linear(output[:, -1])"
   ],
   "id": "2a305f43e10d8fb6",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:31:24.315670Z",
     "start_time": "2025-03-31T11:31:24.301783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Performs one training epoch.\"\"\"\n",
    "    model.train()  # Set model to training mode (enables dropout, etc.)\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Wrap dataloader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for sequences_batch, labels_batch in progress_bar:\n",
    "        # Move data to the selected device\n",
    "        sequences_batch = sequences_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        # --- Forward Pass ---\n",
    "        logits = model(sequences_batch)\n",
    "\n",
    "        # --- Calculate Loss ---\n",
    "        loss = criterion(logits, labels_batch)\n",
    "\n",
    "        # --- Backward Pass and Optimization ---\n",
    "        optimizer.zero_grad() # Clear previous gradients\n",
    "        loss.backward()       # Compute gradients\n",
    "        optimizer.step()      # Update model weights\n",
    "\n",
    "        # --- Track Metrics ---\n",
    "        running_loss += loss.item() * sequences_batch.size(0) # Accumulate weighted loss\n",
    "        total_samples += labels_batch.size(0)\n",
    "\n",
    "        # Calculate accuracy for the batch\n",
    "        with torch.no_grad(): # No need to track gradients for accuracy calculation\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels_batch).item()\n",
    "\n",
    "        # Update progress bar postfix\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=correct_predictions/total_samples)\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluates the model on the given dataset.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Wrap dataloader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation during evaluation\n",
    "        for sequences_batch, labels_batch in progress_bar:\n",
    "            # Move data to the selected device\n",
    "            sequences_batch = sequences_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "\n",
    "            # --- Forward Pass ---\n",
    "            logits = model(sequences_batch)\n",
    "\n",
    "            # --- Calculate Loss ---\n",
    "            loss = criterion(logits, labels_batch)\n",
    "\n",
    "            # --- Track Metrics ---\n",
    "            running_loss += loss.item() * sequences_batch.size(0)\n",
    "            total_samples += labels_batch.size(0)\n",
    "\n",
    "            # Calculate accuracy for the batch\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels_batch).item()\n",
    "\n",
    "            # Update progress bar postfix\n",
    "            progress_bar.set_postfix(loss=loss.item(), acc=correct_predictions/total_samples)\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc"
   ],
   "id": "ef5fdb5c00e34d3a",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:45:28.249344Z",
     "start_time": "2025-03-31T11:44:41.921454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 50\n",
    "embed_len = 128\n",
    "hidden_size = 50\n",
    "num_layers = 3\n",
    "\n",
    "model = RNN(vocab_size, embed_len, hidden_size, num_layers, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1} Training   -> Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, test_loader, loss_fn, device) # Using test_loader as validation\n",
    "    print(f\"Epoch {epoch+1} Validation -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Optional: Add logic here to save the best model based on validation accuracy/loss\n",
    "    # e.g., if val_acc > best_val_acc: save model state_dict\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")"
   ],
   "id": "246c658483f3c7b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training   -> Loss: 1.3814, Accuracy: 0.3105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation -> Loss: 1.3764, Accuracy: 0.3148\n",
      "\n",
      "--- Epoch 2/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training   -> Loss: 1.3753, Accuracy: 0.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation -> Loss: 1.3765, Accuracy: 0.3154\n",
      "\n",
      "--- Epoch 3/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training   -> Loss: 1.3728, Accuracy: 0.3191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation -> Loss: 1.3724, Accuracy: 0.3154\n",
      "\n",
      "--- Epoch 4/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training   -> Loss: 1.3453, Accuracy: 0.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation -> Loss: 1.3913, Accuracy: 0.3345\n",
      "\n",
      "--- Epoch 5/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training   -> Loss: 1.2709, Accuracy: 0.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation -> Loss: 1.3404, Accuracy: 0.3896\n",
      "\n",
      "--- Epoch 6/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training   -> Loss: 1.1518, Accuracy: 0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation -> Loss: 1.3511, Accuracy: 0.3918\n",
      "\n",
      "--- Epoch 7/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training   -> Loss: 1.0521, Accuracy: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation -> Loss: 1.3607, Accuracy: 0.4118\n",
      "\n",
      "--- Epoch 8/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training   -> Loss: 0.9351, Accuracy: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation -> Loss: 1.3749, Accuracy: 0.4360\n",
      "\n",
      "--- Epoch 9/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training   -> Loss: 0.8376, Accuracy: 0.6308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation -> Loss: 1.4157, Accuracy: 0.4297\n",
      "\n",
      "--- Epoch 10/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training   -> Loss: 0.8156, Accuracy: 0.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation -> Loss: 1.3637, Accuracy: 0.4290\n",
      "\n",
      "--- Epoch 11/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training   -> Loss: 0.7579, Accuracy: 0.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation -> Loss: 1.5194, Accuracy: 0.4424\n",
      "\n",
      "--- Epoch 12/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training   -> Loss: 0.7395, Accuracy: 0.6499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation -> Loss: 1.4652, Accuracy: 0.3810\n",
      "\n",
      "--- Epoch 13/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training   -> Loss: 0.7328, Accuracy: 0.6477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation -> Loss: 1.4105, Accuracy: 0.4612\n",
      "\n",
      "--- Epoch 14/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training   -> Loss: 0.6687, Accuracy: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation -> Loss: 1.5151, Accuracy: 0.4513\n",
      "\n",
      "--- Epoch 15/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training   -> Loss: 0.7500, Accuracy: 0.6344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation -> Loss: 1.5922, Accuracy: 0.4208\n",
      "\n",
      "--- Epoch 16/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training   -> Loss: 0.7235, Accuracy: 0.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation -> Loss: 1.6397, Accuracy: 0.4300\n",
      "\n",
      "--- Epoch 17/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training   -> Loss: 0.6692, Accuracy: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation -> Loss: 1.5003, Accuracy: 0.4637\n",
      "\n",
      "--- Epoch 18/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training   -> Loss: 0.6430, Accuracy: 0.6814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Validation -> Loss: 1.5912, Accuracy: 0.4669\n",
      "\n",
      "--- Epoch 19/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training   -> Loss: 0.6630, Accuracy: 0.6978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Validation -> Loss: 1.6133, Accuracy: 0.3918\n",
      "\n",
      "--- Epoch 20/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training   -> Loss: 0.6161, Accuracy: 0.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Validation -> Loss: 1.5815, Accuracy: 0.4574\n",
      "\n",
      "--- Epoch 21/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training   -> Loss: 0.5768, Accuracy: 0.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Validation -> Loss: 1.7065, Accuracy: 0.4545\n",
      "\n",
      "--- Epoch 22/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training   -> Loss: 0.5322, Accuracy: 0.7431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Validation -> Loss: 1.6770, Accuracy: 0.4831\n",
      "\n",
      "--- Epoch 23/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training   -> Loss: 0.5074, Accuracy: 0.7764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Validation -> Loss: 1.7396, Accuracy: 0.4768\n",
      "\n",
      "--- Epoch 24/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training   -> Loss: 0.5127, Accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Validation -> Loss: 1.7100, Accuracy: 0.4615\n",
      "\n",
      "--- Epoch 25/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training   -> Loss: 0.5192, Accuracy: 0.7852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Validation -> Loss: 1.6540, Accuracy: 0.4844\n",
      "\n",
      "--- Epoch 26/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training   -> Loss: 0.4794, Accuracy: 0.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Validation -> Loss: 1.7684, Accuracy: 0.4749\n",
      "\n",
      "--- Epoch 27/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training   -> Loss: 0.4411, Accuracy: 0.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Validation -> Loss: 1.7795, Accuracy: 0.4860\n",
      "\n",
      "--- Epoch 28/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training   -> Loss: 0.5415, Accuracy: 0.7797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Validation -> Loss: 1.7419, Accuracy: 0.4624\n",
      "\n",
      "--- Epoch 29/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training   -> Loss: 0.4576, Accuracy: 0.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Validation -> Loss: 1.7470, Accuracy: 0.5022\n",
      "\n",
      "--- Epoch 30/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training   -> Loss: 0.4727, Accuracy: 0.8226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Validation -> Loss: 1.8394, Accuracy: 0.4637\n",
      "\n",
      "--- Epoch 31/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training   -> Loss: 0.5431, Accuracy: 0.7506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Validation -> Loss: 1.7052, Accuracy: 0.4736\n",
      "\n",
      "--- Epoch 32/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training   -> Loss: 0.4613, Accuracy: 0.8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Validation -> Loss: 1.8057, Accuracy: 0.5003\n",
      "\n",
      "--- Epoch 33/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training   -> Loss: 0.4135, Accuracy: 0.8577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Validation -> Loss: 1.6910, Accuracy: 0.4911\n",
      "\n",
      "--- Epoch 34/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training   -> Loss: 0.4061, Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Validation -> Loss: 1.8268, Accuracy: 0.4984\n",
      "\n",
      "--- Epoch 35/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training   -> Loss: 0.3732, Accuracy: 0.8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Validation -> Loss: 1.8478, Accuracy: 0.5070\n",
      "\n",
      "--- Epoch 36/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training   -> Loss: 0.3627, Accuracy: 0.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Validation -> Loss: 1.8692, Accuracy: 0.5060\n",
      "\n",
      "--- Epoch 37/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training   -> Loss: 0.4091, Accuracy: 0.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Validation -> Loss: 1.8153, Accuracy: 0.4701\n",
      "\n",
      "--- Epoch 38/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training   -> Loss: 0.3817, Accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Validation -> Loss: 1.8183, Accuracy: 0.5302\n",
      "\n",
      "--- Epoch 39/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training   -> Loss: 0.3358, Accuracy: 0.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Validation -> Loss: 1.9033, Accuracy: 0.5143\n",
      "\n",
      "--- Epoch 40/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training   -> Loss: 0.3291, Accuracy: 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Validation -> Loss: 1.9490, Accuracy: 0.5165\n",
      "\n",
      "--- Epoch 41/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training   -> Loss: 0.3808, Accuracy: 0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Validation -> Loss: 1.8270, Accuracy: 0.5162\n",
      "\n",
      "--- Epoch 42/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training   -> Loss: 0.3233, Accuracy: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Validation -> Loss: 2.0308, Accuracy: 0.5045\n",
      "\n",
      "--- Epoch 43/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training   -> Loss: 0.4054, Accuracy: 0.8647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Validation -> Loss: 1.8762, Accuracy: 0.5223\n",
      "\n",
      "--- Epoch 44/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training   -> Loss: 0.3543, Accuracy: 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Validation -> Loss: 1.8439, Accuracy: 0.5111\n",
      "\n",
      "--- Epoch 45/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training   -> Loss: 0.3387, Accuracy: 0.8943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Validation -> Loss: 1.9501, Accuracy: 0.4971\n",
      "\n",
      "--- Epoch 46/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training   -> Loss: 0.4828, Accuracy: 0.7741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Validation -> Loss: 1.8361, Accuracy: 0.4952\n",
      "\n",
      "--- Epoch 47/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training   -> Loss: 0.4118, Accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Validation -> Loss: 1.8585, Accuracy: 0.5086\n",
      "\n",
      "--- Epoch 48/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training   -> Loss: 0.3606, Accuracy: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Validation -> Loss: 1.9777, Accuracy: 0.4892\n",
      "\n",
      "--- Epoch 49/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training   -> Loss: 0.3533, Accuracy: 0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Validation -> Loss: 1.8649, Accuracy: 0.5102\n",
      "\n",
      "--- Epoch 50/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training   -> Loss: 0.3051, Accuracy: 0.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Validation -> Loss: 1.9191, Accuracy: 0.5258\n",
      "\n",
      "--- Training Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 89
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
